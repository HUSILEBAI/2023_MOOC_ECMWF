{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbeucler/2023_MOOC_ECMWF/blob/main/Physically_constrained_postprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook provides a minimal reproducible example of the work described in [link to paper], and contains all the relevant code that is used along with an anonymized version of our data."
      ],
      "metadata": {
        "id": "ZLXdyKxNpBG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up the environment \n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.10\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2\n",
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!python3 get-pip.py --force-reinstall\n",
        "!python3 -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor\n",
        "!ln -s /usr/local/lib/python3.7/dist-packages/google \\\n",
        "       /usr/local/lib/python3.10/dist-packages/google\n",
        "\n",
        "!pip install numpy torch xarray==2022.10.0 netcdf4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nkISju8FQhP",
        "outputId": "281b46ae-a83f-4aec-8fb4-ae09d613a16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,237 kB]\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,144 kB]\n",
            "Fetched 3,662 kB in 5s (785 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython3.10-minimal libpython3.10-stdlib python3.10-minimal\n",
            "Suggested packages:\n",
            "  python3.10-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.10-minimal libpython3.10-stdlib python3.10 python3.10-minimal\n",
            "0 upgraded, 4 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 5,105 kB of archives.\n",
            "After this operation, 19.5 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.10-minimal amd64 3.10.9-1+bionic1 [823 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.10-minimal amd64 3.10.9-1+bionic1 [1,971 kB]\n",
            "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.10-stdlib amd64 3.10.9-1+bionic1 [1,761 kB]\n",
            "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.10 amd64 3.10.9-1+bionic1 [549 kB]\n",
            "Fetched 5,105 kB in 6s (928 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.10-minimal:amd64.\n",
            "(Reading database ... 124016 files and directories currently installed.)\n",
            "Preparing to unpack .../libpython3.10-minimal_3.10.9-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.10-minimal:amd64 (3.10.9-1+bionic1) ...\n",
            "Selecting previously unselected package python3.10-minimal.\n",
            "Preparing to unpack .../python3.10-minimal_3.10.9-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.10-minimal (3.10.9-1+bionic1) ...\n",
            "Selecting previously unselected package libpython3.10-stdlib:amd64.\n",
            "Preparing to unpack .../libpython3.10-stdlib_3.10.9-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.10-stdlib:amd64 (3.10.9-1+bionic1) ...\n",
            "Selecting previously unselected package python3.10.\n",
            "Preparing to unpack .../python3.10_3.10.9-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.10 (3.10.9-1+bionic1) ...\n",
            "Setting up libpython3.10-minimal:amd64 (3.10.9-1+bionic1) ...\n",
            "Setting up libpython3.10-stdlib:amd64 (3.10.9-1+bionic1) ...\n",
            "Setting up python3.10-minimal (3.10.9-1+bionic1) ...\n",
            "Setting up python3.10 (3.10.9-1+bionic1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "update-alternatives: error: alternative path /usr/bin/python3.7 doesn't exist\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2509k  100 2509k    0     0  58.3M      0 --:--:-- --:--:-- --:--:-- 58.3M\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pip\n",
            "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.3.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (7.9.0)\n",
            "Requirement already satisfied: ipython_genutils in /usr/local/lib/python3.8/dist-packages (0.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/dist-packages (5.3.4)\n",
            "Requirement already satisfied: jupyter_console in /usr/local/lib/python3.8/dist-packages (6.1.0)\n",
            "Requirement already satisfied: prompt_toolkit in /usr/local/lib/python3.8/dist-packages (2.0.10)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.8/dist-packages (0.17.4)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython) (4.8.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel) (6.0.4)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel) (6.1.12)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt_toolkit) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt_toolkit) (0.2.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython) (0.8.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel) (23.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel) (2.8.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel) (5.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython) (0.7.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel) (2.6.0)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Collecting xarray==2022.10.0\n",
            "  Downloading xarray-2022.10.0-py3-none-any.whl (947 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m947.6/947.6 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: netcdf4 in /usr/local/lib/python3.8/dist-packages (1.6.2)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.8/dist-packages (from xarray==2022.10.0) (21.3)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.8/dist-packages (from xarray==2022.10.0) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.8/dist-packages (from netcdf4) (1.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=21.0->xarray==2022.10.0) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3->xarray==2022.10.0) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3->xarray==2022.10.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.3->xarray==2022.10.0) (1.15.0)\n",
            "Installing collected packages: xarray\n",
            "  Attempting uninstall: xarray\n",
            "    Found existing installation: xarray 2022.12.0\n",
            "    Uninstalling xarray-2022.12.0:\n",
            "      Successfully uninstalled xarray-2022.12.0\n",
            "Successfully installed xarray-2022.10.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "\n",
        "import pooch\n",
        "import numpy as np \n",
        "import xarray as xr\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch import optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)"
      ],
      "metadata": {
        "id": "8Um5aLtdqjid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuration\n",
        "This is the same configuration used to evaluate the overall performance of our models, as described in the paper."
      ],
      "metadata": {
        "id": "F60g50Ncqdc9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN9207gDJJF2"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 1024\n",
        "ALPHA = 0.995\n",
        "LR = 0.0008\n",
        "UNITS_L1 = 128\n",
        "UNITS_L2 = 256\n",
        "EMBEDDING_SIZE=5\n",
        "MAX_EPOCHS = 20\n",
        "PATIENCE = 5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_data = 'https://unils-my.sharepoint.com/:u:/g/personal/tom_beucler_unil_ch/'"
      ],
      "metadata": {
        "id": "4C6St9NoAF2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_path = path_data + 'EdAG3RBBgk5Kmvo54RPgT2kBp-NJqqGF6Il-gTmh9DbdeA?download=1'\n",
        "y_path = path_data + 'EdVQCVKqnb9Bh495opeuRCEBBZFPDdG0g3xSpIFgNGJeJA?download=1'"
      ],
      "metadata": {
        "id": "Fv_qeYV_Wclr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_open = pooch.retrieve(x_path,known_hash='c6acaf62051b81dfd3d5a4aa516d545615fd2597c8c38f4db4e571a621201878')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhuaFM6S_6Vr",
        "outputId": "471e8076-51a3-413f-a875-4e2dc1a8e8ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading data from 'https://unils-my.sharepoint.com/:u:/g/personal/tom_beucler_unil_ch/EdAG3RBBgk5Kmvo54RPgT2kBp-NJqqGF6Il-gTmh9DbdeA?download=1' to file '/root/.cache/pooch/9cf67a523eb07cc3cce65fc8ca1e7c3a-EdAG3RBBgk5Kmvo54RPgT2kBp-NJqqGF6Il-gTmh9DbdeA'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_open = pooch.retrieve(y_path,known_hash='6265a5f0272e5427c823b95725b8aabbc48a9a97d7554fd5732e6c4b480f3ab3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0my2GwoCS35",
        "outputId": "7a521f8a-ed20-47a9-f846-3da219a5235d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading data from 'https://unils-my.sharepoint.com/:u:/g/personal/tom_beucler_unil_ch/EdVQCVKqnb9Bh495opeuRCEBBZFPDdG0g3xSpIFgNGJeJA?download=1' to file '/root/.cache/pooch/284b1ede27900e4591c2a3de05037b03-EdVQCVKqnb9Bh495opeuRCEBBZFPDdG0g3xSpIFgNGJeJA'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "x = (\n",
        "    xr.open_dataset(x_open)\n",
        "    .set_coords([\"forecast_reference_time\",\"t\", \"station_id\"])\n",
        "    .set_xindex(\"forecast_reference_time\")\n",
        "    .to_array(\"var\")\n",
        "    .transpose(\"s\",\"var\")\n",
        ")\n",
        "y = (\n",
        "    xr.open_dataset(y_open)\n",
        "    .set_coords([\"forecast_reference_time\",\"t\"])\n",
        "    .set_xindex(\"forecast_reference_time\")\n",
        "    .to_array(\"var\")\n",
        "    .transpose(\"s\",\"var\")\n",
        ")"
      ],
      "metadata": {
        "id": "b9qs66zGCkMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data\n",
        "train_sel = dict(forecast_reference_time=slice(\"2017-01-01\",\"2019-12-25\"))\n",
        "val_sel = dict(forecast_reference_time=slice(\"2020-01-01\",\"2020-12-25\"))\n",
        "test_sel = dict(forecast_reference_time=slice(\"2021-01-01\",\"2021-12-31T23:59\"))\n",
        "\n",
        "train_x, train_y = x.sel(train_sel), y.sel(train_sel)\n",
        "val_x, val_y = x.sel(val_sel), y.sel(val_sel)\n",
        "test_x, test_y = x.sel(test_sel), y.sel(test_sel)"
      ],
      "metadata": {
        "id": "vhyeYO4CIHVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize input data\n",
        "train_x_mean = train_x.mean(\"s\")\n",
        "train_x_std = train_x.std(\"s\")\n",
        "\n",
        "train_x = (train_x - train_x_mean) / train_x_std\n",
        "val_x = (val_x - train_x_mean) / train_x_std\n",
        "test_x = (test_x - train_x_mean) / train_x_std"
      ],
      "metadata": {
        "id": "nX7pGRj3EsCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare torch dataloaders\n",
        "\n",
        "class Data(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "\n",
        "        self.x = torch.tensor(x.values).to(\"cuda:0\")\n",
        "        self.y = torch.tensor(y.values).to(\"cuda:0\")\n",
        "        self.station_id = torch.tensor(x.station_id.values, dtype=torch.int32).to(\"cuda:0\")\n",
        "        self.y_coords = y.coords\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.x[idx], self.station_id[idx]), self.y[idx]\n",
        "\n",
        "\n",
        "class DataLoader(object):\n",
        "    def __init__(self, dataset, batch_size, shuffle=False):\n",
        "        self.dataset = dataset\n",
        "        self.dataset_len = self.dataset.x.shape[0]\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        n_batches, remainder = divmod(self.dataset_len, self.batch_size)\n",
        "        if remainder > 0:\n",
        "            n_batches += 1\n",
        "        self.n_batches = n_batches\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self.shuffle:\n",
        "            r = torch.randperm(self.dataset_len)\n",
        "            self.dataset.x = self.dataset.x[r]\n",
        "            self.dataset.station_id = self.dataset.station_id[r]\n",
        "            self.dataset.y = self.dataset.y[r]\n",
        "        self.i = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.i >= self.dataset_len:\n",
        "            raise StopIteration\n",
        "        batch = self.dataset[self.i : self.i + self.batch_size]\n",
        "        self.i += self.batch_size\n",
        "        return batch\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_batches\n",
        "\n",
        "\n",
        "\n",
        "train = Data(train_x, train_y)\n",
        "val = Data(val_x, val_y)\n",
        "\n",
        "train_dl = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dl = DataLoader(val, batch_size=BATCH_SIZE * 8)"
      ],
      "metadata": {
        "id": "0y_do0pJbSiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models and losses\n",
        "\n",
        "- the basic building block for all models is a fully connected architecture wrapped in `Net`, where we initialize the output bias manually to values that are in the same order of magnitude as our targets.\n",
        "- optionally, the module may include the `PhysicsLayer`, which incorporates the physical constraints.\n",
        "- we define the `MultiTaskLoss` class which implements the uncertainty-weighted loss function, and optionally adds the physics-based loss term computed with `physical_penalty`.\n"
      ],
      "metadata": {
        "id": "qetQU2K6rEH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    out_bias = [15.0, 10.0, 900.0, 70.0, 5.0]  # t, t_d, p, rh, r\n",
        "    out_bias_constrained = [15.0, 5.0, 900]  # t, t_def, p\n",
        "\n",
        "    def __init__(self, in_size, n_stations, embedding_size, l1, l2, constraint=False):\n",
        "        super(Net, self).__init__()\n",
        "        self.embedding = nn.Embedding(n_stations, embedding_size)\n",
        "        self.l1 = nn.Linear(in_size + embedding_size, l1)\n",
        "        self.l2 = nn.Linear(l1, l2)\n",
        "        if constraint:\n",
        "            self.out = nn.Sequential(nn.Linear(l2, 3), PhysicsLayer())\n",
        "            self.out[0].bias = nn.Parameter(torch.Tensor(self.out_bias_constrained))\n",
        "        else:\n",
        "            self.out = nn.Linear(l2, 5)\n",
        "            self.out.bias = nn.Parameter(torch.Tensor(self.out_bias))\n",
        "\n",
        "\n",
        "    def forward(self, x, station_id):\n",
        "        station_embedding = self.embedding(station_id)\n",
        "        x = torch.concat([x, station_embedding], dim=-1)\n",
        "        x = torch.relu(self.l1(x))\n",
        "        x = torch.relu(self.l2(x))\n",
        "        out = self.out(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class PhysicsLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PhysicsLayer, self).__init__()\n",
        "\n",
        "    def forward(self, direct):\n",
        "        t, t_def, p = direct[:, 0], direct[:, 1], direct[:, 2]\n",
        "        t_d = t - torch.relu(t_def)\n",
        "        e_s = torch.where(\n",
        "            t >= 0.0,\n",
        "            6.107 * torch.exp((17.368 * t) / (t + 238.83)),\n",
        "            6.108 * torch.exp((17.856 * t) / (t + 245.52)),\n",
        "        )\n",
        "        e = torch.where(\n",
        "            t >= 0.0,\n",
        "            6.107 * torch.exp((17.368 * t_d) / (t_d + 238.83)),\n",
        "            6.108 * torch.exp((17.856 * t_d) / (t_d + 245.52)),\n",
        "        )\n",
        "        rh = e / e_s * 100.0\n",
        "        r = 622.0 * (e / (p - e))\n",
        "        pred = torch.stack([t, t_d, p, rh, r], dim=1)\n",
        "        return pred\n",
        "\n",
        "\n",
        "class MultiTaskLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.0, mask=None, log_var_init=None):\n",
        "        super(MultiTaskLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.mask = [True] * 5 if mask is None else mask\n",
        "\n",
        "        log_var = torch.zeros(5) if log_var_init is None else log_var_init\n",
        "\n",
        "        self.log_var = nn.Parameter(log_var)\n",
        "\n",
        "        self.hp = {\"alpha\": alpha}\n",
        "\n",
        "    def forward(self, pred, y):\n",
        "        loss = torch.mean((pred - y) ** 2, axis=0)\n",
        "        loss = torch.exp(-self.log_var) * loss + self.log_var\n",
        "        loss = torch.sum(loss[self.mask])\n",
        "        rh_res, r_res = physical_penalty(pred)\n",
        "        physics_loss = rh_res / torch.var(y[:, 3]) + r_res / torch.var(y[:, 4])\n",
        "        if self.alpha > 0.0:\n",
        "            loss = (1 - self.alpha) * loss + self.alpha * physics_loss\n",
        "        return loss, physics_loss\n",
        "\n",
        "\n",
        "def physical_penalty(pred):\n",
        "    t, t_d, p, rh, r = pred[:, 0], pred[:, 1], pred[:, 2], pred[:, 3], pred[:, 4]\n",
        "    e = torch.where(\n",
        "        t >= 0.0,\n",
        "        6.107 * torch.exp((17.368 * t_d) / (t_d + 238.83)),\n",
        "        6.108 * torch.exp((17.856 * t_d) / (t_d + 245.52)),\n",
        "    )\n",
        "    e_s = torch.where(\n",
        "        t >= 0.0,\n",
        "        6.107 * torch.exp((17.368 * t) / (t + 238.83)),\n",
        "        6.108 * torch.exp((17.856 * t) / (t + 245.52)),\n",
        "    )\n",
        "    rh_derived = e / (e_s + 1e-5) * 100.0\n",
        "    r_derived = 622.0 * (e / (p - e))\n",
        "\n",
        "    return (\n",
        "        torch.mean((rh_derived - rh) ** 2),\n",
        "        torch.mean((r_derived - r) ** 2),\n",
        "    )"
      ],
      "metadata": {
        "id": "_YdmVebMgvfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training functions\n",
        "\n",
        "def training_step(model, loss_fn, optimizer, train_dataloader):\n",
        "    model.train(True)\n",
        "    loss_fn.train(True)\n",
        "    running_loss = 0.0\n",
        "    num_batches = len(train_dataloader)\n",
        "    iterator = enumerate(train_dataloader)\n",
        "    for i, (X, y) in iterator:\n",
        "        pred = model(*X)\n",
        "        loss, p = loss_fn(pred, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / num_batches\n",
        "\n",
        "\n",
        "def validation_step(model, loss_fn, val_dataloader):\n",
        "    model.train(False), loss_fn.train(False)\n",
        "    val_loss = 0.0\n",
        "    val_p = 0.0\n",
        "    val_mae = 0.0\n",
        "    with torch.no_grad():\n",
        "        iterator = val_dataloader\n",
        "        for X, y in iterator:\n",
        "            pred = model(*X)\n",
        "            loss, p = loss_fn(pred, y)\n",
        "            val_loss += loss.item()\n",
        "            val_p += p.item()\n",
        "            val_mae += torch.mean(torch.abs(pred - y), dim=0)\n",
        "    val_loss /= len(val_dataloader)\n",
        "    val_p /= len(val_dataloader)\n",
        "    val_mae /= len(val_dataloader)\n",
        "    return val_loss, val_p, val_mae\n",
        "\n",
        "\n",
        "def fit(model, loss_fn, train_dl, val_dl, max_epochs=20, max_patience=5):\n",
        "    optimizer = optim.Adam(\n",
        "        chain(model.parameters(), loss_fn.parameters()), lr=LR\n",
        "    )\n",
        "    best_val_nmae = torch.inf\n",
        "    val_y_std = val.y.std(dim=0)\n",
        "    for epoch in range(max_epochs):\n",
        "\n",
        "        train_loss = training_step(model, loss_fn, optimizer, train_dl)\n",
        "        val_loss, val_p, val_mae = validation_step(model, loss_fn, val_dl)\n",
        "        val_nmae = torch.mean((val_mae / val_y_std))\n",
        "\n",
        "        if val_nmae < best_val_nmae:\n",
        "            best_val_nmae = val_nmae\n",
        "            best_model = model\n",
        "            patience = 0\n",
        "        else:\n",
        "            patience += 1\n",
        "            if patience == max_patience:\n",
        "                break\n",
        "\n",
        "        print(\n",
        "            f\"{epoch+1:<2}{'':>4}loss: {train_loss:<10.4}val_loss: {val_loss:<10.4}\"\n",
        "            f\"val_t_mae: {val_mae[0]:<10.4} val_rh_mae: {val_mae[3]:<10.4}\"\n",
        "            f\"val_nmae: {val_nmae:<10.4} val_p: {val_p:<10.4}\"\n",
        "        )\n",
        "\n",
        "    return best_model"
      ],
      "metadata": {
        "id": "RrmlW5ZogwNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJG9f6gYg54I",
        "outputId": "ce962716-39cd-46a5-cb71-48d41db3b87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "unconstrained = Net(\n",
        "    11, 131, EMBEDDING_SIZE, UNITS_L1, UNITS_L2, constraint=False\n",
        ").to(\"cuda:0\")\n",
        "loss = MultiTaskLoss().to(\"cuda:0\")\n",
        "\n",
        "unconstrained = fit(unconstrained, loss, train_dl, val_dl, max_epochs=20, max_patience=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5k5zF5vgxpd",
        "outputId": "5f4a3150-2c87-4a8d-d3f1-6e248dc86e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1     loss: 127.8     val_loss: 14.1      val_t_mae: 1.529      val_rh_mae: 9.658     val_nmae: 0.218      val_p: 0.03546   \n",
            "2     loss: 13.66     val_loss: 13.51     val_t_mae: 1.5        val_rh_mae: 9.527     val_nmae: 0.2146     val_p: 0.02282   \n",
            "3     loss: 13.47     val_loss: 13.41     val_t_mae: 1.497      val_rh_mae: 9.454     val_nmae: 0.2135     val_p: 0.02837   \n",
            "4     loss: 13.4      val_loss: 13.33     val_t_mae: 1.475      val_rh_mae: 9.364     val_nmae: 0.2116     val_p: 0.03328   \n",
            "5     loss: 13.34     val_loss: 13.38     val_t_mae: 1.498      val_rh_mae: 9.354     val_nmae: 0.2126     val_p: 0.05927   \n",
            "6     loss: 13.31     val_loss: 13.32     val_t_mae: 1.471      val_rh_mae: 9.384     val_nmae: 0.2121     val_p: 0.03494   \n",
            "7     loss: 13.28     val_loss: 13.31     val_t_mae: 1.465      val_rh_mae: 9.301     val_nmae: 0.2106     val_p: 0.02914   \n",
            "8     loss: 13.26     val_loss: 13.3      val_t_mae: 1.46       val_rh_mae: 9.276     val_nmae: 0.2101     val_p: 0.02525   \n",
            "9     loss: 13.24     val_loss: 13.28     val_t_mae: 1.467      val_rh_mae: 9.274     val_nmae: 0.2106     val_p: 0.03921   \n",
            "10    loss: 13.22     val_loss: 13.34     val_t_mae: 1.462      val_rh_mae: 9.298     val_nmae: 0.2106     val_p: 0.02575   \n",
            "11    loss: 13.21     val_loss: 13.24     val_t_mae: 1.457      val_rh_mae: 9.262     val_nmae: 0.2098     val_p: 0.0182    \n",
            "12    loss: 13.19     val_loss: 13.28     val_t_mae: 1.455      val_rh_mae: 9.25      val_nmae: 0.21       val_p: 0.02606   \n",
            "13    loss: 13.18     val_loss: 13.26     val_t_mae: 1.451      val_rh_mae: 9.192     val_nmae: 0.2093     val_p: 0.02661   \n",
            "14    loss: 13.17     val_loss: 13.25     val_t_mae: 1.445      val_rh_mae: 9.182     val_nmae: 0.2092     val_p: 0.04308   \n",
            "15    loss: 13.16     val_loss: 13.25     val_t_mae: 1.445      val_rh_mae: 9.189     val_nmae: 0.2085     val_p: 0.01775   \n",
            "16    loss: 13.15     val_loss: 13.24     val_t_mae: 1.453      val_rh_mae: 9.185     val_nmae: 0.2087     val_p: 0.01868   \n",
            "17    loss: 13.14     val_loss: 13.28     val_t_mae: 1.445      val_rh_mae: 9.192     val_nmae: 0.2093     val_p: 0.02309   \n",
            "18    loss: 13.13     val_loss: 13.24     val_t_mae: 1.447      val_rh_mae: 9.198     val_nmae: 0.2091     val_p: 0.02414   \n",
            "19    loss: 13.12     val_loss: 13.27     val_t_mae: 1.45       val_rh_mae: 9.194     val_nmae: 0.2093     val_p: 0.02724   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_num_threads(2)\n",
        "\n",
        "architecture_constrained = Net(\n",
        "    11, 131, EMBEDDING_SIZE, UNITS_L1, UNITS_L2, constraint=True\n",
        ").to(\"cuda:0\")\n",
        "loss = MultiTaskLoss().to(\"cuda:0\")\n",
        "\n",
        "architecture_constrained = fit(architecture_constrained, loss, train_dl, val_dl, max_epochs=20, max_patience=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tMIDaKlhG9U",
        "outputId": "bcae8dd8-29df-43b5-b385-85f2567d2e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1     loss: 119.7     val_loss: 14.09     val_t_mae: 1.542      val_rh_mae: 9.599     val_nmae: 0.218      val_p: 3.05e-11  \n",
            "2     loss: 13.67     val_loss: 13.48     val_t_mae: 1.509      val_rh_mae: 9.577     val_nmae: 0.2154     val_p: 2.971e-11 \n",
            "3     loss: 13.49     val_loss: 13.5      val_t_mae: 1.491      val_rh_mae: 9.369     val_nmae: 0.2131     val_p: 2.957e-11 \n",
            "4     loss: 13.42     val_loss: 13.37     val_t_mae: 1.484      val_rh_mae: 9.22      val_nmae: 0.2103     val_p: 3.112e-11 \n",
            "5     loss: 13.37     val_loss: 13.35     val_t_mae: 1.481      val_rh_mae: 9.341     val_nmae: 0.2114     val_p: 3.02e-11  \n",
            "6     loss: 13.34     val_loss: 13.41     val_t_mae: 1.473      val_rh_mae: 9.221     val_nmae: 0.2114     val_p: 3.193e-11 \n",
            "7     loss: 13.32     val_loss: 13.3      val_t_mae: 1.479      val_rh_mae: 9.186     val_nmae: 0.2093     val_p: 3.152e-11 \n",
            "8     loss: 13.3      val_loss: 13.33     val_t_mae: 1.478      val_rh_mae: 9.188     val_nmae: 0.2097     val_p: 3.081e-11 \n",
            "9     loss: 13.28     val_loss: 13.33     val_t_mae: 1.477      val_rh_mae: 9.169     val_nmae: 0.2093     val_p: 3.181e-11 \n",
            "10    loss: 13.26     val_loss: 13.31     val_t_mae: 1.466      val_rh_mae: 9.181     val_nmae: 0.2093     val_p: 3.168e-11 \n",
            "11    loss: 13.25     val_loss: 13.34     val_t_mae: 1.464      val_rh_mae: 9.158     val_nmae: 0.2092     val_p: 3.104e-11 \n",
            "12    loss: 13.23     val_loss: 13.32     val_t_mae: 1.466      val_rh_mae: 9.221     val_nmae: 0.2094     val_p: 3.143e-11 \n",
            "13    loss: 13.22     val_loss: 13.31     val_t_mae: 1.465      val_rh_mae: 9.214     val_nmae: 0.2097     val_p: 3.013e-11 \n",
            "14    loss: 13.21     val_loss: 13.3      val_t_mae: 1.476      val_rh_mae: 9.221     val_nmae: 0.2103     val_p: 3.265e-11 \n",
            "15    loss: 13.2      val_loss: 13.29     val_t_mae: 1.463      val_rh_mae: 9.191     val_nmae: 0.2088     val_p: 3.032e-11 \n",
            "16    loss: 13.19     val_loss: 13.32     val_t_mae: 1.471      val_rh_mae: 9.283     val_nmae: 0.2102     val_p: 2.852e-11 \n",
            "17    loss: 13.18     val_loss: 13.28     val_t_mae: 1.449      val_rh_mae: 9.327     val_nmae: 0.2101     val_p: 2.922e-11 \n",
            "18    loss: 13.18     val_loss: 13.34     val_t_mae: 1.469      val_rh_mae: 9.196     val_nmae: 0.21       val_p: 2.987e-11 \n",
            "19    loss: 13.17     val_loss: 13.28     val_t_mae: 1.476      val_rh_mae: 9.091     val_nmae: 0.2079     val_p: 3.361e-11 \n",
            "20    loss: 13.16     val_loss: 13.31     val_t_mae: 1.46       val_rh_mae: 9.137     val_nmae: 0.2089     val_p: 3.227e-11 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_constrained = Net(\n",
        "    11, 131, EMBEDDING_SIZE, UNITS_L1, UNITS_L2, constraint=False\n",
        ").to(\"cuda:0\")\n",
        "constrained_loss = MultiTaskLoss(alpha=ALPHA).to(\"cuda:0\")\n",
        "\n",
        "loss_constrained = fit(loss_constrained, constrained_loss, train_dl, val_dl, max_epochs=20, max_patience=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADKMsMVyny2f",
        "outputId": "81e07765-dd5d-4763-e889-ead9ba5399b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1     loss: 0.661     val_loss: 0.07373   val_t_mae: 1.561      val_rh_mae: 9.753     val_nmae: 0.2199     val_p: 0.002564  \n",
            "2     loss: 0.06939   val_loss: 0.06902   val_t_mae: 1.53       val_rh_mae: 9.642     val_nmae: 0.2168     val_p: 0.001339  \n",
            "3     loss: 0.06841   val_loss: 0.07015   val_t_mae: 1.52       val_rh_mae: 9.607     val_nmae: 0.2161     val_p: 0.002464  \n",
            "4     loss: 0.06804   val_loss: 0.0682    val_t_mae: 1.504      val_rh_mae: 9.515     val_nmae: 0.2144     val_p: 0.0009904 \n",
            "5     loss: 0.0678    val_loss: 0.06812   val_t_mae: 1.501      val_rh_mae: 9.495     val_nmae: 0.2139     val_p: 0.0009515 \n",
            "6     loss: 0.06763   val_loss: 0.06784   val_t_mae: 1.489      val_rh_mae: 9.477     val_nmae: 0.2132     val_p: 0.0009112 \n",
            "7     loss: 0.06748   val_loss: 0.06794   val_t_mae: 1.489      val_rh_mae: 9.49      val_nmae: 0.2132     val_p: 0.0008872 \n",
            "8     loss: 0.06736   val_loss: 0.06807   val_t_mae: 1.497      val_rh_mae: 9.469     val_nmae: 0.2132     val_p: 0.001011  \n",
            "9     loss: 0.06725   val_loss: 0.06772   val_t_mae: 1.483      val_rh_mae: 9.413     val_nmae: 0.2121     val_p: 0.0009313 \n",
            "10    loss: 0.06716   val_loss: 0.06768   val_t_mae: 1.478      val_rh_mae: 9.369     val_nmae: 0.2114     val_p: 0.0009502 \n",
            "11    loss: 0.06707   val_loss: 0.06918   val_t_mae: 1.481      val_rh_mae: 9.413     val_nmae: 0.2118     val_p: 0.002379  \n",
            "12    loss: 0.06699   val_loss: 0.06857   val_t_mae: 1.488      val_rh_mae: 9.408     val_nmae: 0.212      val_p: 0.00178   \n",
            "13    loss: 0.06691   val_loss: 0.06778   val_t_mae: 1.481      val_rh_mae: 9.351     val_nmae: 0.2109     val_p: 0.001211  \n",
            "14    loss: 0.06684   val_loss: 0.0678    val_t_mae: 1.472      val_rh_mae: 9.352     val_nmae: 0.2109     val_p: 0.0009547 \n",
            "15    loss: 0.06677   val_loss: 0.0679    val_t_mae: 1.47       val_rh_mae: 9.291     val_nmae: 0.21       val_p: 0.001321  \n",
            "16    loss: 0.06671   val_loss: 0.06759   val_t_mae: 1.473      val_rh_mae: 9.297     val_nmae: 0.2099     val_p: 0.001176  \n",
            "17    loss: 0.06665   val_loss: 0.0676    val_t_mae: 1.484      val_rh_mae: 9.338     val_nmae: 0.2108     val_p: 0.0009193 \n",
            "18    loss: 0.06659   val_loss: 0.06762   val_t_mae: 1.473      val_rh_mae: 9.341     val_nmae: 0.2107     val_p: 0.0009418 \n",
            "19    loss: 0.06654   val_loss: 0.0674    val_t_mae: 1.467      val_rh_mae: 9.299     val_nmae: 0.2098     val_p: 0.0009861 \n",
            "20    loss: 0.06649   val_loss: 0.06759   val_t_mae: 1.459      val_rh_mae: 9.272     val_nmae: 0.2091     val_p: 0.001216  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = Data(test_x, test_y)\n",
        "test_dl = DataLoader(test, batch_size=BATCH_SIZE * 16)\n",
        "\n",
        "\n",
        "def evaluate(model, test_dl):\n",
        "    model.eval()\n",
        "    mae, mse = 0.0, 0.0\n",
        "    with torch.no_grad():\n",
        "        iterator = test_dl\n",
        "        for X, y in iterator:\n",
        "            pred = model(*X)\n",
        "            mae += torch.mean(torch.abs(pred - y), dim=0)\n",
        "            mse += torch.mean((pred - y)**2, dim=0)\n",
        "    return mae / len(test_dl), mse / len(test_dl) "
      ],
      "metadata": {
        "id": "MIvT4CYX5mwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(unconstrained, test_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8I-iZBb55uc",
        "outputId": "8f54c03e-6088-404d-8ac9-5c0a5f692dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.5000, 1.6534, 0.9950, 9.3079, 0.5917], device='cuda:0'),\n",
              " tensor([  3.9038,   5.4306,   2.1298, 150.9891,   0.6418], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(architecture_constrained, test_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpglf0xW562M",
        "outputId": "a15132a6-8f1b-4343-8cb4-a9a7bb3828c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.5040, 1.6675, 1.0268, 9.3120, 0.5956], device='cuda:0'),\n",
              " tensor([  3.9215,   5.5530,   2.2092, 154.3734,   0.6595], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(loss_constrained, test_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrmqRpyQ7WuB",
        "outputId": "d2e06560-2545-4a06-f28b-780ef77f69ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.5001, 1.6435, 1.0024, 9.3098, 0.5825], device='cuda:0'),\n",
              " tensor([  3.9243,   5.5040,   2.1578, 151.1862,   0.6311], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3zlKIWK57dDR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}